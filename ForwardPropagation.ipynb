{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fYVWLzOJ8BUy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MzkrMgCpZIlx"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import graphviz\n",
        "import pandas as pd\n",
        "\n",
        "def sigmoid(x):\n",
        "    return 1 / (1 + np.exp(-x))\n",
        "\n",
        "def relu(x):\n",
        "    return np.maximum(0, x)\n",
        "\n",
        "def tanh(x):\n",
        "    return np.tanh(x)\n",
        "\n",
        "def standardize_data(X, standardize=True):\n",
        "    if standardize:\n",
        "        # Ensure X is in a numeric format\n",
        "        try:\n",
        "            X = X.astype(float)  # Convert to float (assuming all values can be converted to float)\n",
        "        except ValueError:\n",
        "            print(\"Cannot convert some values to float.\")\n",
        "            return X\n",
        "\n",
        "        # Select columns with finite (non-NaN, non-inf) values\n",
        "        numeric_columns = np.all(np.isfinite(X), axis=0)\n",
        "        X = X[:, numeric_columns]\n",
        "\n",
        "        # Calculate mean and standard deviation only for numeric columns\n",
        "        mean = np.mean(X, axis=0)\n",
        "        std = np.std(X, axis=0)\n",
        "\n",
        "        # Standardize the data\n",
        "        X_standardized = (X - mean) / std\n",
        "\n",
        "        # Replace non-numeric columns with standardized numeric columns\n",
        "        X_result = np.empty_like(X)\n",
        "        X_result[:, numeric_columns] = X_standardized\n",
        "\n",
        "        return X_result\n",
        "    else:\n",
        "        return X\n",
        "\n",
        "\n",
        "\n",
        "def forward_pass(input_data, num_neurons, activation_functions):\n",
        "    # Generate random weights for connections between neurons\n",
        "    weights = [np.random.rand(num_neurons[i], num_neurons[i+1]) for i in range(len(num_neurons)-1)]\n",
        "\n",
        "    # Generate random biases for each neuron\n",
        "    biases = [np.random.rand(num_neurons[i+1]) for i in range(len(num_neurons)-1)]\n",
        "\n",
        "    # Forward pass\n",
        "    activations = [input_data]\n",
        "    for i in range(len(num_neurons)-1):\n",
        "        z = np.dot(activations[-1], weights[i]) + biases[i]\n",
        "        #z = np.dot(np.array(activations[-1]), weights[i]) + biases[i]\n",
        "        if activation_functions[i] == 'sigmoid':\n",
        "            a = sigmoid(z)\n",
        "        elif activation_functions[i] == 'relu':\n",
        "            a = relu(z)\n",
        "        elif activation_functions[i] == 'tanh':\n",
        "            a = tanh(z)\n",
        "        activations.append(a)\n",
        "\n",
        "    # Visualize the neural network using graphviz\n",
        "    dot = graphviz.Digraph()\n",
        "\n",
        "    for layer in range(len(num_neurons)):\n",
        "        for neuron in range(num_neurons[layer]):\n",
        "            dot.node(f'Layer_{layer}_Neuron_{neuron}', label=f'Layer {layer}\\nNeuron {neuron}')\n",
        "\n",
        "    for layer in range(len(num_neurons)-1):\n",
        "        for i in range(num_neurons[layer]):\n",
        "            for j in range(num_neurons[layer+1]):\n",
        "                dot.edge(f'Layer_{layer}_Neuron_{i}', f'Layer_{layer+1}_Neuron_{j}')\n",
        "\n",
        "    dot.render('neural_network', format='png', cleanup=True)\n",
        "    dot.view()\n",
        "\n",
        "# Load the dataset\n",
        "file_path = \"/content/drive/MyDrive/31-01-2024/fab.csv\"  # Replace 'your_dataset.csv' with the actual path to your dataset\n",
        "data = pd.read_csv(file_path)\n",
        "\n",
        "# Extract features and target variable\n",
        "X = data.iloc[:, :-1].values\n",
        "\n",
        "# Standardize the input data\n",
        "X_standardized = standardize_data(X)\n",
        "\n",
        "# Take input from the user\n",
        "num_neurons = [X_standardized.shape[1], 5, 3]  # Example architecture: input layer has same number of neurons as features, followed by a hidden layer of 5 neurons and output layer of 3 neurons\n",
        "activation_functions = ['relu', 'sigmoid']  # Example activation functions for each layer\n",
        "\n",
        "# Perform forward pass using the dataset\n",
        "forward_pass(X_standardized[0], num_neurons, activation_functions)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ls5PXtPZNiF",
        "outputId": "14846c3b-1861-41cf-f02f-83740e662587"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import graphviz\n",
        "import pandas as pd\n",
        "\n",
        "def sigmoid(x):\n",
        "    return 1 / (1 + np.exp(-x))\n",
        "\n",
        "def relu(x):\n",
        "    return np.maximum(0, x)\n",
        "\n",
        "def tanh(x):\n",
        "    return np.tanh(x)\n",
        "\n",
        "def standardize_data(X, standardize=True):\n",
        "    if standardize:\n",
        "        # Ensure X is in a numeric format\n",
        "        try:\n",
        "            X = X.astype(float)  # Convert to float (assuming all values can be converted to float)\n",
        "        except ValueError:\n",
        "            print(\"Cannot convert some values to float.\")\n",
        "            return X\n",
        "\n",
        "        # Select columns with finite (non-NaN, non-inf) values\n",
        "        numeric_columns = np.all(np.isfinite(X), axis=0)\n",
        "        X = X[:, numeric_columns]\n",
        "\n",
        "        # Calculate mean and standard deviation only for numeric columns\n",
        "        mean = np.mean(X, axis=0)\n",
        "        std = np.std(X, axis=0)\n",
        "\n",
        "        # Standardize the data\n",
        "        X_standardized = (X - mean) / std\n",
        "\n",
        "        # Replace non-numeric columns with standardized numeric columns\n",
        "        X_result = np.empty_like(X)\n",
        "        X_result[:, numeric_columns] = X_standardized\n",
        "\n",
        "        return X_result\n",
        "    else:\n",
        "        return X\n",
        "\n",
        "def forward_pass(input_data, num_neurons, activation_functions):\n",
        "    # Generate random weights for connections between neurons\n",
        "    weights = [np.random.rand(num_neurons[i], num_neurons[i+1]) for i in range(len(num_neurons)-1)]\n",
        "\n",
        "    # Generate random biases for each neuron\n",
        "    biases = [np.random.rand(num_neurons[i+1]) for i in range(len(num_neurons)-1)]\n",
        "\n",
        "    # Forward pass\n",
        "    activations = [input_data]\n",
        "    for i in range(len(num_neurons)-1):\n",
        "        z = np.dot(activations[-1], weights[i]) + biases[i]\n",
        "        if activation_functions[i] == 'sigmoid':\n",
        "            a = sigmoid(z)\n",
        "        elif activation_functions[i] == 'relu':\n",
        "            a = relu(z)\n",
        "        elif activation_functions[i] == 'tanh':\n",
        "            a = tanh(z)\n",
        "        activations.append(a)\n",
        "\n",
        "    # Output of the last layer\n",
        "    last_layer_output = activations[-1]\n",
        "\n",
        "    return last_layer_output\n",
        "\n",
        "# Prompt user to input number of neurons and layers\n",
        "num_layers = int(input(\"Enter the number of layers: \"))\n",
        "num_neurons = []\n",
        "for layer in range(num_layers):\n",
        "    neurons = int(input(f\"Enter the number of neurons for layer {layer+1}: \"))\n",
        "    num_neurons.append(neurons)\n",
        "\n",
        "# Define activation functions for each layer\n",
        "activation_functions = []\n",
        "for layer in range(num_layers - 1):\n",
        "    activation = input(f\"Enter the activation function for layer {layer+1} (sigmoid, relu, tanh): \")\n",
        "    activation_functions.append(activation)\n",
        "\n",
        "# Load the dataset\n",
        "file_path = \"/content/drive/MyDrive/31-01-2024/fab.csv\"  # Replace 'your_dataset.csv' with the actual path to your dataset\n",
        "data = pd.read_csv(file_path)\n",
        "\n",
        "# Extract features and target variable\n",
        "X = data.iloc[:, :-1].values\n",
        "\n",
        "# Standardize the input data\n",
        "X_standardized = standardize_data(X)\n",
        "\n",
        "# Perform forward pass using the dataset\n",
        "output = forward_pass(X_standardized, num_neurons, activation_functions)\n",
        "print(\"Output of the last layer nodes:\", output)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d3Gm3VKgSU1P",
        "outputId": "d114e292-b4ee-4e5b-8e64-ea98691b9d0e"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter the number of layers: 3\n",
            "Enter the number of neurons for layer 1: 2\n",
            "Enter the number of neurons for layer 2: 2\n",
            "Enter the number of neurons for layer 3: 1\n",
            "Enter the activation function for layer 1 (sigmoid, relu, tanh): sigmoid\n",
            "Enter the activation function for layer 2 (sigmoid, relu, tanh): sigmoid\n",
            "Output of the last layer nodes: [[0.7324309 ]\n",
            " [0.79108919]\n",
            " [0.77506797]\n",
            " [0.82222571]]\n"
          ]
        }
      ]
    }
  ]
}